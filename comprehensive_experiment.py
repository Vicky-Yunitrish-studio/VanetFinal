#!/usr/bin/env python3
"""
å¤§è¦æ¨¡ç¶œåˆå¯¦é©—é¡
ç”¨æ–¼é‹è¡Œä¸€è¬æ¬¡å¯¦é©—çš„æ ¸å¿ƒå¯¦é©—é¡
"""

import time
import json
import numpy as np
from datetime import datetime
from algorithm.agent import QLearningAgent
from module.urban_grid import UrbanGrid
from vehicle import Vehicle
from algorithm.reward_config import RewardConfig


class ComprehensiveExperiment:
    """ç¶œåˆå¯¦é©—é¡ï¼Œæ”¯æŒå¤§è¦æ¨¡å¯¦é©—é‹è¡Œ"""
    
    def __init__(self, grid_size=20):
        """åˆå§‹åŒ–å¯¦é©—ç’°å¢ƒ
        
        Args:
            grid_size: ç¶²æ ¼å¤§å°
        """
        self.grid_size = grid_size
        self.results = []
        
    def run_single_experiment(self, algorithm_type, obstacle_density, congestion_level, 
                            num_episodes=10000, max_steps=300):
        """é‹è¡Œå–®å€‹å¯¦é©—é…ç½®
        
        Args:
            algorithm_type: æ¼”ç®—æ³•é¡å‹ ('proximity_based' æˆ– 'exponential_distance')
            obstacle_density: éšœç¤™ç‰©å¯†åº¦ (0.1, 0.25 ç­‰)
            congestion_level: å£…å¡ç¨‹åº¦ ('low' æˆ– 'high')
            num_episodes: å¯¦é©—å›åˆæ•¸
            max_steps: æ¯å›åˆæœ€å¤§æ­¥æ•¸
            
        Returns:
            å¯¦é©—çµæœå­—å…¸
        """
        print(f"ğŸ§ª é–‹å§‹å¯¦é©—: {algorithm_type}, å¯†åº¦{obstacle_density}, å£…å¡{congestion_level}")
        print(f"ğŸ“Š å›åˆæ•¸: {num_episodes}, æœ€å¤§æ­¥æ•¸: {max_steps}")
        
        # è¨­ç½®çå‹µé…ç½®
        reward_config = RewardConfig()
        reward_config.set_algorithm_type(algorithm_type)
        
        # æ ¹æ“šæ¼”ç®—æ³•é¡å‹èª¿æ•´åƒæ•¸
        if algorithm_type == "exponential_distance":
            reward_config.update_config(
                exp_base_reward=-1,
                exp_amplitude=40,
                exp_x_scale=1.5,
                exp_y_scale=2.0,
                step_penalty=0  # ç”±æŒ‡æ•¸å‡½æ•¸è™•ç†
            )
        
        # å‰µå»ºç’°å¢ƒ
        urban_grid = UrbanGrid(size=self.grid_size)
        
        # è¨­ç½®éšœç¤™ç‰©å¯†åº¦
        num_obstacles = int(obstacle_density * self.grid_size * self.grid_size)
        np.random.seed(42)  # ä¿è­‰å¯é‡ç¾æ€§
        for _ in range(num_obstacles):
            x, y = np.random.randint(0, self.grid_size, 2)
            urban_grid.add_obstacle(x, y)
        
        # è¨­ç½®å£…å¡ç¨‹åº¦
        if congestion_level == 'high':
            urban_grid.congestion = np.random.uniform(0.3, 0.8, size=(self.grid_size, self.grid_size))
        else:  # low
            urban_grid.congestion = np.random.uniform(0.0, 0.3, size=(self.grid_size, self.grid_size))
        
        # å‰µå»ºä»£ç†
        agent = QLearningAgent(urban_grid, learning_rate=0.1, discount_factor=0.95, epsilon=0.1)
        
        # å¯¦é©—çµ±è¨ˆ
        success_count = 0
        total_steps = 0
        total_rewards = 0
        path_lengths = []
        computation_times = []
        
        # é€²åº¦é¡¯ç¤ºé–“éš”
        progress_interval = max(1, num_episodes // 20)  # æ¯5%é¡¯ç¤ºä¸€æ¬¡
        
        start_time = time.time()
        
        for episode in range(num_episodes):
            # éš¨æ©Ÿè¨­ç½®èµ·é»å’Œçµ‚é»
            start_pos = self._get_random_valid_position(urban_grid)
            end_pos = self._get_random_valid_position(urban_grid)
            
            # ç¢ºä¿èµ·é»å’Œçµ‚é»ä¸åŒ
            while start_pos == end_pos:
                end_pos = self._get_random_valid_position(urban_grid)
            
            # å‰µå»ºè»Šè¼›
            vehicle = Vehicle(urban_grid, agent, reward_config=reward_config)
            vehicle.position = start_pos
            vehicle.destination = end_pos
            vehicle.path = [start_pos]
            
            # é‹è¡Œå–®å›åˆ
            episode_start_time = time.time()
            success, steps, total_reward = self._run_single_episode(
                vehicle, agent, urban_grid, max_steps
            )
            episode_time = time.time() - episode_start_time
            
            # çµ±è¨ˆçµæœ
            if success:
                success_count += 1
                path_lengths.append(steps)
            
            total_steps += steps
            total_rewards += total_reward
            computation_times.append(episode_time * 1000)  # è½‰æ›ç‚ºæ¯«ç§’
            
            # é€²åº¦é¡¯ç¤º
            if (episode + 1) % progress_interval == 0:
                progress = (episode + 1) / num_episodes * 100
                current_success_rate = success_count / (episode + 1)
                print(f"é€²åº¦: {progress:.1f}% ({episode + 1}/{num_episodes}), "
                      f"æˆåŠŸç‡: {current_success_rate:.3f}")
        
        experiment_time = time.time() - start_time
        
        # è¨ˆç®—æœ€çµ‚çµ±è¨ˆ
        success_rate = success_count / num_episodes
        avg_steps = total_steps / num_episodes
        avg_reward = total_rewards / num_episodes
        avg_computation_time = np.mean(computation_times)
        
        # è·¯å¾‘æ•ˆç‡è¨ˆç®— (æˆåŠŸæ¡ˆä¾‹çš„å¹³å‡æ­¥æ•¸ vs ç†è«–æœ€çŸ­è·¯å¾‘)
        if path_lengths:
            avg_successful_steps = np.mean(path_lengths)
            # ç°¡åŒ–çš„æ•ˆç‡ä¼°ç®— (å¯¦éš›æ‡‰è©²ç”¨A*è¨ˆç®—æœ€çŸ­è·¯å¾‘)
            estimated_optimal_steps = self.grid_size * 0.6  # ç²—ç•¥ä¼°ç®—
            path_efficiency = estimated_optimal_steps / avg_successful_steps if avg_successful_steps > 0 else 0
        else:
            path_efficiency = 0
        
        result = {
            'algorithm_type': algorithm_type,
            'obstacle_density': obstacle_density,
            'congestion_level': congestion_level,
            'num_episodes': num_episodes,
            'success_rate': success_rate,
            'avg_steps': avg_steps,
            'avg_reward': avg_reward,
            'path_efficiency': path_efficiency,
            'avg_computation_time': avg_computation_time,
            'experiment_time': experiment_time,
            'successful_episodes': success_count,
            'total_steps': total_steps,
            'total_rewards': total_rewards
        }
        
        print(f"âœ… å¯¦é©—å®Œæˆ:")
        print(f"   æˆåŠŸç‡: {success_rate:.4f}")
        print(f"   å¹³å‡æ­¥æ•¸: {avg_steps:.2f}")
        print(f"   å¹³å‡çå‹µ: {avg_reward:.2f}")
        print(f"   è·¯å¾‘æ•ˆç‡: {path_efficiency:.4f}")
        print(f"   å¹³å‡è¨ˆç®—æ™‚é–“: {avg_computation_time:.2f}ms")
        print(f"   å¯¦é©—ç¸½æ™‚é–“: {experiment_time/60:.1f}åˆ†é˜")
        
        return result
    
    def _get_random_valid_position(self, urban_grid):
        """ç²å–éš¨æ©Ÿæœ‰æ•ˆä½ç½®ï¼ˆä¸åœ¨éšœç¤™ç‰©ä¸Šï¼‰"""
        while True:
            x, y = np.random.randint(0, urban_grid.size, 2)
            if not urban_grid.obstacles[x, y]:
                return (x, y)
    
    def _run_single_episode(self, vehicle, agent, urban_grid, max_steps):
        """é‹è¡Œå–®å€‹å›åˆ
        
        Returns:
            (success, steps, total_reward)
        """
        # è¨­ç½®ä»£ç†çš„ç›®æ¨™ä½ç½®ï¼ˆç”¨æ–¼ç‹€æ…‹è¨ˆç®—ï¼‰
        agent.current_destination = vehicle.destination
        
        total_reward = 0
        steps = 0
        
        for step in range(max_steps):
            # æª¢æŸ¥æ˜¯å¦åˆ°é”ç›®æ¨™
            if vehicle.position == vehicle.destination or vehicle.reached:
                return True, steps, total_reward
            
            # è»Šè¼›ç§»å‹•ï¼ˆåŒ…å«ç‹€æ…‹ã€å‹•ä½œã€çå‹µã€Qè¡¨æ›´æ–°ï¼‰
            reward = vehicle.move()
            
            total_reward += reward
            steps += 1
            
            # æ›´æ–°ç’°å¢ƒ
            urban_grid.update_traffic_lights()
            urban_grid.update_congestion([vehicle.position])
        
        # æœªåœ¨æœ€å¤§æ­¥æ•¸å…§åˆ°é”
        return False, steps, total_reward
    
    def analyze_results(self):
        """åˆ†æå¯¦é©—çµæœ"""
        if not self.results:
            return {}
        
        analysis = {
            'total_experiments': len(self.results),
            'overall_success_rate': np.mean([r['success_rate'] for r in self.results]),
            'overall_avg_steps': np.mean([r['avg_steps'] for r in self.results]),
            'overall_avg_reward': np.mean([r['avg_reward'] for r in self.results]),
            'overall_path_efficiency': np.mean([r['path_efficiency'] for r in self.results]),
            'overall_avg_computation_time': np.mean([r['avg_computation_time'] for r in self.results]),
            'by_algorithm': {},
            'by_density': {},
            'by_congestion': {}
        }
        
        # æŒ‰æ¼”ç®—æ³•åˆ†æ
        algorithms = set(r['algorithm_type'] for r in self.results)
        for algo in algorithms:
            algo_results = [r for r in self.results if r['algorithm_type'] == algo]
            analysis['by_algorithm'][algo] = {
                'success_rate': np.mean([r['success_rate'] for r in algo_results]),
                'avg_steps': np.mean([r['avg_steps'] for r in algo_results]),
                'avg_reward': np.mean([r['avg_reward'] for r in algo_results]),
                'path_efficiency': np.mean([r['path_efficiency'] for r in algo_results]),
                'avg_computation_time': np.mean([r['avg_computation_time'] for r in algo_results])
            }
        
        # æŒ‰å¯†åº¦åˆ†æ
        densities = set(r['obstacle_density'] for r in self.results)
        for density in densities:
            density_results = [r for r in self.results if r['obstacle_density'] == density]
            analysis['by_density'][density] = {
                'success_rate': np.mean([r['success_rate'] for r in density_results]),
                'avg_steps': np.mean([r['avg_steps'] for r in density_results]),
                'avg_reward': np.mean([r['avg_reward'] for r in density_results])
            }
        
        # æŒ‰å£…å¡ç¨‹åº¦åˆ†æ
        congestion_levels = set(r['congestion_level'] for r in self.results)
        for level in congestion_levels:
            level_results = [r for r in self.results if r['congestion_level'] == level]
            analysis['by_congestion'][level] = {
                'success_rate': np.mean([r['success_rate'] for r in level_results]),
                'avg_steps': np.mean([r['avg_steps'] for r in level_results]),
                'avg_reward': np.mean([r['avg_reward'] for r in level_results])
            }
        
        return analysis
    
    def save_results(self, analysis=None):
        """ä¿å­˜å¯¦é©—çµæœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜åŸå§‹çµæœ
        results_filename = f'experiment_results_{timestamp}.json'
        with open(results_filename, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜åˆ†æçµæœ
        if analysis:
            analysis_filename = f'experiment_analysis_{timestamp}.json'
            with open(analysis_filename, 'w', encoding='utf-8') as f:
                json.dump(analysis, f, indent=2, ensure_ascii=False)
        
        # ä¿å­˜CSVæ ¼å¼çµæœ
        csv_filename = f'experiment_results_{timestamp}.csv'
        with open(csv_filename, 'w', encoding='utf-8') as f:
            # å¯«å…¥æ¨™é¡Œ
            f.write('algorithm_type,obstacle_density,congestion_level,success_rate,avg_steps,avg_reward,path_efficiency,avg_computation_time\n')
            
            # å¯«å…¥æ•¸æ“š
            for result in self.results:
                f.write(f"{result['algorithm_type']},{result['obstacle_density']},{result['congestion_level']},"
                       f"{result['success_rate']:.6f},{result['avg_steps']:.4f},{result['avg_reward']:.4f},"
                       f"{result['path_efficiency']:.6f},{result['avg_computation_time']:.4f}\n")
        
        print(f"ğŸ“ çµæœå·²ä¿å­˜:")
        print(f"   JSON: {results_filename}")
        if analysis:
            print(f"   åˆ†æ: {analysis_filename}")
        print(f"   CSV: {csv_filename}")
        
        return results_filename, analysis_filename if analysis else None, csv_filename


if __name__ == "__main__":
    # æ¸¬è©¦å¯¦é©—é¡
    print("ğŸ§ª æ¸¬è©¦ ComprehensiveExperiment é¡")
    experiment = ComprehensiveExperiment(grid_size=10)
    
    # é‹è¡Œå°è¦æ¨¡æ¸¬è©¦
    result = experiment.run_single_experiment(
        'proximity_based', 0.1, 'low', 
        num_episodes=100, max_steps=100
    )
    
    print("âœ… æ¸¬è©¦å®Œæˆï¼Œå¯¦é©—é¡æ­£å¸¸é‹ä½œ")
