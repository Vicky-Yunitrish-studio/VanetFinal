# A*æ¼”ç®—æ³•+é„°è¿‘æ¼”ç®—æ³•

## æœ¬ç³»çµ±

### 1. é„°è¿‘æ€§æ¦‚å¿µåœ¨ç³»çµ±ä¸­çš„é«”ç¾

#### A. **å‹•ä½œé¸æ“‡çš„é„°è¿‘æ€§**

```python
def get_valid_actions(self, position):
    """Get valid actions at current position (avoiding grid boundaries and obstacles)"""
    valid_actions = []
    for i, (dx, dy) in enumerate(self.actions):  # [(0,1), (1,0), (0,-1), (-1,0)]
        new_x = position[0] + dx
        new_y = position[1] + dy
        # åªè€ƒæ…®ç›¸é„°çš„å››å€‹ä½ç½® - é€™å°±æ˜¯é„°è¿‘æ€§æ¦‚å¿µï¼
```

**é„°è¿‘æ€§é«”ç¾**ï¼š

- æ‚¨çš„ç³»çµ±åªè€ƒæ…®ç•¶å‰ä½ç½®çš„**ç›´æ¥ç›¸é„°ä½ç½®**ï¼ˆä¸Šä¸‹å·¦å³å››å€‹æ–¹å‘ï¼‰
- é€™æ­£æ˜¯é„°è¿‘æ¼”ç®—æ³•çš„æ ¸å¿ƒï¼š**å±€éƒ¨æœç´¢**ï¼Œåªè€ƒæ…®é™„è¿‘çš„é¸é …

#### B. **åŸºæ–¼è·é›¢çš„çå‹µæ©Ÿåˆ¶**

**ç¨‹å¼ç¢¼å¯¦ç¾**ï¼š

```python
def calculate_reward_proximity_based(self, new_position, dx, dy):
    # --- Proximity reward: the closer to the destination, the higher the reward ---
    old_dist = manhattan_dist(self.position, self.destination)
    new_dist = manhattan_dist(new_position, self.destination)
    proximity_reward = old_dist - new_dist  # è¶Šè¿‘çå‹µè¶Šé«˜
    
    # è·é›¢è¶Šè¿‘ï¼Œçå‹µå€æ•¸è¶Šé«˜
    progress = 1 - (new_dist / max_possible_dist)
    proximity_multiplier = base_multiplier + (max_multiplier * progress)
    reward += proximity_reward * proximity_multiplier
```

**æ•¸å­¸å…¬å¼ç‰ˆæœ¬**ï¼š

##### ğŸ“ åŸºç¤é„°è¿‘çå‹µå‡½æ•¸

**æ›¼å“ˆé “è·é›¢**ï¼š

$d(pâ‚, pâ‚‚) = |xâ‚ - xâ‚‚| + |yâ‚ - yâ‚‚|$

**é„°è¿‘æ€§çå‹µ**ï¼š

$R_{proximity} = d(s_t, g) - d(s_{t+1}, g)$

å…¶ä¸­ï¼š

- $s_t = ç•¶å‰ä½ç½® (current position)$
- $s_{t+1} = ä¸‹ä¸€å€‹ä½ç½® (next position)$  
- $g = ç›®æ¨™ä½ç½® (goal position)$
- $d(x,y) = æ›¼å“ˆé “è·é›¢å‡½æ•¸$

##### ğŸ“Š å‹•æ…‹å€æ•¸çå‹µå‡½æ•¸

**é€²åº¦è¨ˆç®—**ï¼š

$progress = 1 - d(s_{t+1}, g) / d_{max}$

**é„°è¿‘å€æ•¸**ï¼š

$M_{proximity} = Î±_{base} + Î±_{max} Ã— progress$

**æœ€çµ‚é„°è¿‘çå‹µ**ï¼š

$R_{proximity  final} = R_{proximity} Ã— M_{proximity}$

##### ğŸ¯ å®Œæ•´çå‹µå‡½æ•¸

**ç¸½çå‹µå‡½æ•¸**ï¼š

$R_{total} = R_{step} + R_{proximity final} + R_{astar} + R_{congestion} + R_{loop}$

å±•é–‹ç‚ºï¼š

$R_{total} = Î²_{step} + [d(s_t,g) - d(s_{t+1},g)] Ã— [Î±_{base} + Î±_{max} Ã— (1 - d(s_{t+1},g)/d_{max})] + R_{astar} + R_{congestion} + R_{loop}$

**åƒæ•¸èªªæ˜**ï¼š

- $Î²_{step} = åŸºç¤æ­¥æ•¸æ‡²ç½° (é€šå¸¸ç‚ºè² å€¼)$
- $Î±_{base} = åŸºç¤é„°è¿‘å€æ•¸$
- $Î±_{max} = æœ€å¤§é„°è¿‘å€æ•¸$
- $d_{max} = ç¶²æ ¼æœ€å¤§å¯èƒ½è·é›¢ = 2 Ã— grid size$
- $R_{asta} = \text{A*è·¯å¾‘è·Ÿéš¨çå‹µ}$
- $R_{congestion} = æ“å¡æ‡²ç½°$
- $R_{loop} = è¿´è·¯æ‡²ç½°$

##### ğŸ”¢ å…¸å‹åƒæ•¸å€¼

- $Î²_{step} = -1          \quad\text {æ¯æ­¥åŸºç¤æ‡²ç½°}$
- $Î±_{base} = 1.0         \quad\text { åŸºç¤å€æ•¸}$
- $Î±_{max} = 3.0          \quad\text { æœ€å¤§å€æ•¸}$
- $d_{max} = 40           \quad\text { å°æ–¼20Ã—20ç¶²æ ¼}$

##### ğŸ“ˆ çå‹µå‡½æ•¸æ€§è³ªåˆ†æ

**è·é›¢çå‹µç‰¹æ€§**ï¼š

- ç•¶ $d(s_{t+1}, g) < d(s_t, g)$ æ™‚ï¼Œ$R_{proximity} > 0$ (é è¿‘ç›®æ¨™)
- ç•¶ $d(s_{t+1}, g) > d(s_t, g)$ æ™‚ï¼Œ$R_{proximity} < 0$ (é é›¢ç›®æ¨™)
- ç•¶ $d(s_{t+1}, g) = d(s_t, g)$ æ™‚ï¼Œ$R_{proximity} = 0$ (è·é›¢ä¸è®Š)

**å€æ•¸æ•ˆæ‡‰**ï¼š

- è·é›¢ç›®æ¨™è¶Šè¿‘ï¼Œå€æ•¸è¶Šå¤§ï¼Œçå‹µæ”¾å¤§æ•ˆæœè¶Šå¼·
- åœ¨ç›®æ¨™é™„è¿‘ï¼š$M_{proximity} â‰ˆ Î±_{base} + Î±_{max} â‰ˆ 4.0$
- åœ¨èµ·å§‹ä½ç½®ï¼š$M_{proximity} â‰ˆ Î±_{base} â‰ˆ 1.0$

#### C. **ç‹€æ…‹è¡¨ç¤ºä¸­çš„æ–¹å‘æ„ŸçŸ¥**

```python
def get_state_key(self, position, congestion_level):
    # Get direction to destination (discretized to 8 directions)
    if hasattr(self, 'current_destination'):
        dx = self.current_destination[0] - position[0]
        dy = self.current_destination[1] - position[1]
        angle = np.arctan2(dy, dx)
        direction = int(((angle + np.pi) * 4 / np.pi + 0.5) % 8)
```

**é„°è¿‘æ€§é«”ç¾**ï¼š

- ç‹€æ…‹è¡¨ç¤ºåŒ…å«äº†**æœå‘ç›®æ¨™çš„æ–¹å‘**
- é€™å¹«åŠ©æ™ºèƒ½é«”å„ªå…ˆé¸æ“‡æœå‘ç›®æ¨™çš„ç›¸é„°ä½ç½®

### 2. æˆ‘å€‘çš„ç³»çµ± vs ç´”é„°è¿‘æ¼”ç®—æ³•

| ç‰¹æ€§ | ç´”é„°è¿‘æ¼”ç®—æ³• | A*+Q-learning+é„°è¿‘æ¼”ç®—æ³• |
|------|-------------|------------------|
| **æœç´¢ç¯„åœ** | åªè€ƒæ…®ç›¸é„°ä½ç½® | âœ… ä¹Ÿåªè€ƒæ…®ç›¸é„°ä½ç½® |
| **è·é›¢åå¥½** | é¸æ“‡è·é›¢ç›®æ¨™æœ€è¿‘çš„ç›¸é„°ä½ç½® | âœ… çå‹µé è¿‘ç›®æ¨™çš„ç§»å‹• |
| **æ±ºç­–æ©Ÿåˆ¶** | è²ªå©ªé¸æ“‡ | ğŸ”„ çµåˆå­¸ç¿’çš„è²ªå©ªé¸æ“‡ |
| **å…¨å±€è¦åŠƒ** | âŒ ç„¡ | âœ… æœ‰ï¼ˆA*æŒ‡å°ï¼‰ |
| **å­¸ç¿’èƒ½åŠ›** | âŒ ç„¡ | âœ… æœ‰ï¼ˆQ-learningï¼‰ |

### 3. å‰µæ–°ä¹‹è™•

#### A. **å¤šå±¤æ¬¡çš„é„°è¿‘æ€§**

**ç¨‹å¼ç¢¼å¯¦ç¾**ï¼š

```python
# 1. å³æ™‚é„°è¿‘æ€§ï¼ˆå‚³çµ±é„°è¿‘æ¼”ç®—æ³•ï¼‰
proximity_reward = old_dist - new_dist

# 2. è·¯å¾‘é„°è¿‘æ€§ï¼ˆA*æŒ‡å°çš„é„°è¿‘ï¼‰
if new_position == next_optimal:
    reward += astar_rewards['follow']  # çå‹µè·Ÿéš¨A*è·¯å¾‘

# 3. æ­·å²é„°è¿‘æ€§ï¼ˆé¿å…é‡è¤‡è¨ªå•ï¼‰
if new_position in self.position_history:
    # æ‡²ç½°é‡è¤‡è¨ªå•ç›¸åŒä½ç½®
```

**æ•¸å­¸å…¬å¼ç‰ˆæœ¬**ï¼š

##### ğŸ¯ A*è·¯å¾‘è·Ÿéš¨çå‹µ

**è·¯å¾‘è·é›¢å‡½æ•¸**ï¼š

$d_{path}(s, P) = \text{min }{d(s, p_i) | p_i âˆˆ P}$

å…¶ä¸­ $P = \{pâ‚, pâ‚‚, ..., p_n\}$ æ˜¯A*æœ€å„ªè·¯å¾‘

**è·¯å¾‘è·Ÿéš¨çå‹µ**ï¼š

$R_{a star} = \begin{cases}
    Î³_{\text{ follow }},     \text { if } s_{t+1} = p_{next} \\
    Î³_{\text{ on path }},    \text { if } s_{t+1} âˆˆ P \\
    0,            \text { otherwise }
\end{cases}$

**è·¯å¾‘é€²åº¦çå‹µ**ï¼š

$R_{\text{ path progress}} = Î³_{\text{base}} Ã— max(0, 1 - d_{path}(s_{t+1}, P)/Ïƒ_{path}) Ã— (i/|P|)$

åƒæ•¸èªªæ˜ï¼š

- $Î³_{follow} = ç›´æ¥è·Ÿéš¨A*è·¯å¾‘çš„é«˜çå‹µ$
- $Î³_{\text{on path}} = åœ¨A*è·¯å¾‘ä¸Šçš„ä¸­ç­‰çå‹µ$
- $Î³_{base} = è·¯å¾‘è·é›¢åŸºç¤çå‹µ$
- $Ïƒ_{path} = è·¯å¾‘è·é›¢æ‡²ç½°ä¿‚æ•¸$
- $i= åœ¨è·¯å¾‘ä¸­çš„ä½ç½®ç´¢å¼•$
- $|P|= è·¯å¾‘ç¸½é•·åº¦$

##### ğŸ”„ è¿´è·¯æ‡²ç½°å‡½æ•¸

**ä½ç½®è¨ªå•é »ç‡**ï¼š

$freq(s) = |\{t | s_t = s, t â‰¤ \text{current time}\}|$

**è¿´è·¯æ‡²ç½°**ï¼š

$
R_{loop} = \begin{cases}
    Î»_{loop} Ã— (freq(s_{t+1}) - Î¸_{loop}),  \quad \text{if  } freq(s_{t+1}) > Î¸_loop \\
    0,\quad \text{otherwise}
\end{cases}
$

åƒæ•¸èªªæ˜ï¼š

- $Î»_{loop} = è¿´è·¯æ‡²ç½°ä¿‚æ•¸ (è² å€¼)$
- $Î¸_{loop} = è¿´è·¯æª¢æ¸¬é–¾å€¼$

##### ğŸš¦ æ“å¡æ‡²ç½°å‡½æ•¸

**æ“å¡æ‡²ç½°**ï¼š

$
R_{congestion} = \begin{cases}
    Î¼_{congestion} Ã— C(s_{t+1}), \quad \text{if  }C(s_{t+1}) > Î¸_{congestion} \\
    0, \quad \text{otherwise}
\end{cases}
$

å…¶ä¸­ï¼š

- $C(s) = ä½ç½®sçš„æ“å¡ç¨‹åº¦ âˆˆ [0,1]$
- $Î¼_{congestion} = æ“å¡æ‡²ç½°ä¿‚æ•¸ (è² å€¼)$
- $Î¸_{congestion} = æ“å¡æ‡²ç½°é–¾å€¼$

##### ğŸ² å®Œæ•´å¤šå±¤æ¬¡çå‹µå‡½æ•¸

**ç¶œåˆçå‹µå‡½æ•¸**ï¼š

$R_{total}(s_t, a_t, s_{t+1}) = R_{base} + R_{proximity} + R_{astar} + R_{congestion} + R_{loop}$

å±•é–‹ç‚ºï¼š

$
$R_{total} = Î²_{step} + [d(s_t,g) - d(s_{t+1},g)] Ã— M_{proximity} + R_{astar}(s_{t+1}, P) + R_{congestion}(s_{t+1}) + R_{loop}(s_{t+1})$

##### ğŸ“Š å…¸å‹åƒæ•¸é…ç½®

- $Î²_{step} = -1.0           \qquad\text{åŸºç¤æ­¥æ•¸æ‡²ç½°}$
- $Î±_{base} = 1.0            \qquad\text{é„°è¿‘åŸºç¤å€æ•¸}$
- $Î±_{max} = 3.0             \qquad\text{é„°è¿‘æœ€å¤§å€æ•¸}$
- $Î³_{follow} = 3.0          \qquad\text{A*è·Ÿéš¨çå‹µ}$
- $Î³_{on_path} = 1.0         \qquad\text{A*è·¯å¾‘çå‹µ}$
- $Î³_{base} = 2.0            \qquad\text{è·¯å¾‘è·é›¢åŸºç¤çå‹µ}$
- $Ïƒ_{path} = 2.0            \qquad\text{è·¯å¾‘è·é›¢ä¿‚æ•¸}$
- $Î»_{loop} = -20.0          \qquad\text{è¿´è·¯æ‡²ç½°ä¿‚æ•¸}$
- $Î¸_{loop} = 3              \qquad\text{è¿´è·¯é–¾å€¼}$
- $Î¼_{congestion} = -10.0    \qquad\text{æ“å¡æ‡²ç½°ä¿‚æ•¸}$
- $Î¸_{congestion} = 0.5      \qquad\text{æ“å¡é–¾å€¼}$

##### ğŸ¯ çå‹µå‡½æ•¸æœ€ä½³åŒ–ç‰¹æ€§

**æ¢¯åº¦ç‰¹æ€§**ï¼š

- è·é›¢æ¢¯åº¦ï¼šå¼•å°æ™ºèƒ½é«”æœç›®æ¨™ç§»å‹•
- è·¯å¾‘æ¢¯åº¦ï¼šå¼•å°æ™ºèƒ½é«”è·Ÿéš¨æœ€å„ªè·¯å¾‘
- æ‡²ç½°æ¢¯åº¦ï¼šé¿å…ä¸è‰¯è¡Œç‚ºï¼ˆè¿´è·¯ã€æ“å¡ï¼‰

**æ”¶æ–‚æ€§**ï¼š

- åœ¨ç„¡æ“å¡ã€ç„¡éšœç¤™çš„ç†æƒ³ç’°å¢ƒä¸­ï¼Œè©²çå‹µå‡½æ•¸ä¿è­‰æ”¶æ–‚åˆ°æœ€å„ªè§£
- å¤šå±¤æ¬¡è¨­è¨ˆç¢ºä¿åœ¨è¤‡é›œç’°å¢ƒä¸­ä¹Ÿèƒ½æ‰¾åˆ°è¿‘ä¼¼æœ€å„ªè§£

#### B. **æ™ºèƒ½åŒ–çš„é„°è¿‘é¸æ“‡**

**ç¨‹å¼ç¢¼å¯¦ç¾**ï¼š

```python
def choose_action(self, state, position):
    if random.random() < self.epsilon:
        return random.choice(valid_actions)  # æ¢ç´¢
    else:
        # åœ¨ç›¸é„°ä½ç½®ä¸­é¸æ“‡Qå€¼æœ€é«˜çš„ï¼ˆå­¸ç¿’éçš„æœ€å„ªé„°è¿‘é¸æ“‡ï¼‰
        q_values = [self.q_table[state][a] for a in valid_actions]
        max_q = max(q_values)
```

**æ•¸å­¸å…¬å¼ç‰ˆæœ¬**ï¼š

##### ğŸ§  Q-learningå‹•ä½œé¸æ“‡

**Îµ-è²ªå©ªç­–ç•¥**ï¼š

$
Ï€(a|s) = \begin{cases}
    1 - Îµ + Îµ/|A(s)|,  if a = argmax*Q(s,a') \\
    Îµ/|A(s)|, \quad\text{otherwise} \\
\end{cases}
$

**å‹•ä½œé¸æ“‡å‡½æ•¸**ï¼š

$
a_t = \begin{cases}
    random(A(s_t)), \quad\text{with probability Îµ} \\
    argmax_{aâˆˆA(s_t)} Q(s_t,a), \quad\text{with probability 1 - Îµ} \\
\end{cases}
$

å…¶ä¸­ï¼š

- $A(s) = ç‹€æ…‹sä¸‹çš„æœ‰æ•ˆå‹•ä½œé›†åˆ(ç›¸é„°ä½ç½®)$
- $Îµ = æ¢ç´¢ç‡$
- $Q(s,a)= ç‹€æ…‹-å‹•ä½œåƒ¹å€¼å‡½æ•¸$

##### ğŸ¯ Qå€¼æ›´æ–°å‡½æ•¸

**Q-learningæ›´æ–°è¦å‰‡**ï¼š

$Q(s_t, a_t) â† Q(s_t, a_t) + Î±[r_{t+1} + Î³*max_{a'} Q(s_{t+1}, a') - Q(s_t, a_t)]$

**æ™‚é–“å·®åˆ†èª¤å·®**ï¼š

$Î´_t = r_{t+1} + Î³*max_{a'} Q(s_{t+1}, a') - Q(s_t, a_t)$

**ç°¡åŒ–æ›´æ–°å½¢å¼**ï¼š

$Q(s_t, a_t) â† (1-Î±)Q(s_t, a_t) + Î±[r_{t+1} + Î³ max_{a'} Q(s_{t+1}, a')]$

åƒæ•¸èªªæ˜ï¼š

- $Î± = å­¸ç¿’ç‡ âˆˆ [0,1] $
- $Î³ = æŠ˜æ‰£å› å­ âˆˆ [0,1]$
- $r_{t+1} = å³æ™‚çå‹µ(ä½¿ç”¨å‰é¢å®šç¾©çš„çå‹µå‡½æ•¸)$

##### ğŸ—ºï¸ ç‹€æ…‹è¡¨ç¤ºå‡½æ•¸

**ç‹€æ…‹ç·¨ç¢¼**ï¼š

$s = (x, y, c_{discrete}, Î¸_{direction})$

**æ“å¡é›¢æ•£åŒ–**ï¼š

$c_{discrete} = âŒŠC(x,y) Ã— 5âŒ‹ âˆˆ {0,1,2,3,4}$

**æ–¹å‘é›¢æ•£åŒ–**ï¼š

$Î¸_{direction} = âŒŠ(arctan2(g_y - y, g_x - x) + Ï€) Ã— 4/Ï€ + 0.5âŒ‹ mod\quad8$

å…¶ä¸­$(g_x, g_y)$æ˜¯ç›®æ¨™ä½ç½®ã€‚

### 4. æ¼”ç®—æ³•åˆ†é¡

æ‚¨çš„ç³»çµ±å¯ä»¥è¢«åˆ†é¡ç‚ºï¼š

```graph
A*+Q-learningæ··åˆæ¼”ç®—æ³•
â”œâ”€â”€ ğŸ¯ å…¨å±€è¦åŠƒå±¤ï¼šA*æ¼”ç®—æ³•
â”‚   â””â”€â”€ æä¾›æœ€å„ªè·¯å¾‘æŒ‡å°
â”œâ”€â”€ ğŸ§  å­¸ç¿’å±¤ï¼šQ-learning
â”‚   â””â”€â”€ å¾ç¶“é©—ä¸­å­¸ç¿’æœ€ä½³é„°è¿‘é¸æ“‡
â””â”€â”€ ğŸ“ åŸ·è¡Œå±¤ï¼šå¢å¼·é„°è¿‘æ¼”ç®—æ³•
    â”œâ”€â”€ åŸºç¤é„°è¿‘æ€§ï¼ˆè·é›¢å°å‘ï¼‰
    â”œâ”€â”€ è·¯å¾‘é„°è¿‘æ€§ï¼ˆA*å°å‘ï¼‰
    â””â”€â”€ å­¸ç¿’é„°è¿‘æ€§ï¼ˆQå€¼å°å‘ï¼‰
```


---

## ğŸ“ **æ•¸å­¸æ¨¡å‹ç¸½çµ**

### ğŸ¯ å®Œæ•´çš„A*+Q-learningæ··åˆæ¼”ç®—æ³•æ•¸å­¸æ¡†æ¶

#### é¦¬å¯å¤«æ±ºç­–éç¨‹å®šç¾©

**ç‹€æ…‹ç©ºé–“**ï¼š

$
S = \{(x, y, c, Î¸) | x,y âˆˆ [0, \text{grid-size}-1], c âˆˆ [0,4], Î¸ âˆˆ [0,7]\}
$

**å‹•ä½œç©ºé–“**ï¼š

$
A = \{North, East, South, West\} = \{(0,1), (1,0), (0,-1), (-1,0)\}
$

**è½‰ç§»å‡½æ•¸**ï¼š

$
P(s'|s,a) = \begin{cases}
    1,  \text{if }s' = (x+dx, y+dy, c', Î¸')\text{ and action }a = (dx,dy) \\
    0,  otherwise
\end{cases}
$

**çå‹µå‡½æ•¸**ï¼š

$
R(s,a,s') = R_{distance}(s,s') + R_{astar}(s') + R_{congestion}(s') + R_{loop}(s')
$

å…¶ä¸­è·é›¢çå‹µå¯é¸æ“‡ï¼š

- **é„°è¿‘æ€§ç®—æ³•**ï¼š$R_{distance} = [d(s,g) - d(s',g)] Ã— M_{proximity}$
- **æŒ‡æ•¸è·é›¢ç®—æ³•**ï¼š$R_{distance} = Î²_{exp} + Î»_{exp} Ã— exp(-d_{norm}(s',g))$

#### å®Œæ•´çå‹µå‡½æ•°å±•é–‹

**é„°è¿‘æ€§ç‰ˆæœ¬**ï¼š

$
R_{total} = -1 + [d(s,g) - d(s',g)] Ã— [Î±_{base} + Î±_{max} Ã— (1 - d(s',g)/d_{max})] \\
        + Î³_{astar}(s', P) + Î¼_{congestion} Ã— C(s') + Î»_{loop} Ã— freq(s')
$

**æŒ‡æ•¸è·é›¢ç‰ˆæœ¬**ï¼š

$
R_{total} = Î²_{exp} + Î»_{exp} Ã— exp(-[|x_s' - x_g|/Ïƒ_x + |y_s' - y_g|/Ïƒ_y])
        + Î³_{astar}(s', P) + Î¼_{congestion} Ã— C(s') + Î»_{loop} Ã— freq(s')
$

#### Q-learningåƒ¹å€¼è¿­ä»£

**ç‹€æ…‹åƒ¹å€¼å‡½æ•¸**ï¼š

$
V'(s) = max_a Q'(s,a)
$

**æœ€å„ªQå‡½æ•¸**ï¼š

$
Q'(s,a) = E[R(s,a,s') + Î³*V'(s')]
$

**è¿­ä»£æ›´æ–°**ï¼š

$
Q_{k+1}(s,a) = Q_k(s,a) + Î±[r + Î³*max_{a'} Q_k(s',a') - Q_k(s,a)]
$

#### A*è·¯å¾‘è¦åŠƒæ•´åˆ

**å•Ÿç™¼å¼å‡½æ•¸**ï¼š

$
h(s,g) = |x_s - x_g| + |y_s - y_g| + w_{congestion} Ã— C(s)
$

**A*è©•ä¼°å‡½æ•¸**ï¼š

$
f(s) = g(s) + h(s,goal)
$

å…¶ä¸­$g(s)$æ˜¯å¾èµ·é»åˆ°sçš„å¯¦éš›ä»£åƒ¹ã€‚

#### ç­–ç•¥å‡½æ•¸

**æœ€å„ªç­–ç•¥**ï¼š

$
Ï€*(s) = argmax_a Q*(s,a)
$

**Îµ-è²ªå©ªæ¢ç´¢ç­–ç•¥**ï¼š

$
Ï€_Îµ(s) = \begin{cases}
    Ï€*(s),           \text{with probability } 1-Îµ \\
    random(A(s)),    \text{with probability } Îµ
\end{cases}
$

### ğŸ² å…¸å‹åƒæ•¸é…ç½®ç¸½è¡¨

| åƒæ•¸ | ç¬¦è™Ÿ | æ•¸å€¼ç¯„åœ | å»ºè­°å€¼ | èªªæ˜ |
|------|------|----------|--------|------|
| å­¸ç¿’ç‡ | Î± | (0,1] | 0.2 | Qå€¼æ›´æ–°é€Ÿåº¦ |
| æŠ˜æ‰£å› å­ | Î³ | [0,1] | 0.95 | æœªä¾†çå‹µé‡è¦æ€§ |
| æ¢ç´¢ç‡ | Îµ | [0,1] | 0.2 | éš¨æ©Ÿæ¢ç´¢æ¦‚ç‡ |
| æ­¥æ•¸æ‡²ç½° | Î²_step | (-âˆ,0] | -1.0 | é¼“å‹µçŸ­è·¯å¾‘ |
| é„°è¿‘åŸºç¤å€æ•¸ | Î±_base | [0,âˆ) | 1.0 | åŸºç¤é„°è¿‘çå‹µ |
| é„°è¿‘æœ€å¤§å€æ•¸ | Î±_max | [0,âˆ) | 3.0 | æ¥è¿‘ç›®æ¨™æ™‚çš„çå‹µå€æ•¸ |
| A*è·Ÿéš¨çå‹µ | Î³_follow | [0,âˆ) | 3.0 | ç›´æ¥è·Ÿéš¨A*è·¯å¾‘ |
| A*è·¯å¾‘çå‹µ | Î³_on_path | [0,âˆ) | 1.0 | åœ¨A*è·¯å¾‘ä¸Š |
| è¿´è·¯æ‡²ç½°ä¿‚æ•¸ | Î»_loop | (-âˆ,0] | -20.0 | é¿å…ç„¡é™è¿´è·¯ |
| æ“å¡æ‡²ç½°ä¿‚æ•¸ | Î¼_congestion | (-âˆ,0] | -10.0 | é¿å…æ“å¡å€åŸŸ |

